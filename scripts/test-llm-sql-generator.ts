/**
 * Manual utility for exercising the LLM SQL generator end-to-end.
 *
 * Usage:
 *   ts-node scripts/test-llm-sql-generator.ts <customerId> "<user question>" [modelId]
 *
 * The script calls generateSQLWithLLM with a minimal synthetic context. It
 * requires a configured database connection for the provided customer Id and
 * valid AI provider credentials (the same prerequisites as the application).
 */

import { randomUUID } from "crypto";
import { generateSQLWithLLM } from "@/lib/services/semantic/llm-sql-generator.service";
import type { ContextBundle } from "@/lib/services/context-discovery/types";
import { DEFAULT_AI_MODEL_ID } from "@/lib/config/ai-models";

async function main(): Promise<void> {
  const [, , customerIdArg, questionArg, modelIdArg] = process.argv;
  const customerId = customerIdArg?.trim();
  const question =
    questionArg?.trim() ||
    "How many female patients did we treat in the last 30 days?";
  const modelId = modelIdArg?.trim() || DEFAULT_AI_MODEL_ID;

  if (!customerId) {
    console.error(
      "Usage: ts-node scripts/test-llm-sql-generator.ts <customerId> \"<user question>\" [modelId]"
    );
    process.exit(1);
  }

  const context: ContextBundle = {
    customerId,
    question,
    intent: {
      type: "operational_metrics",
      scope: "aggregate",
      metrics: ["count"],
      filters: [],
      confidence: 0.75,
      reasoning:
        "Synthetic context generated by scripts/test-llm-sql-generator.ts",
    },
    forms: [],
    terminology: [],
    joinPaths: [],
    overallConfidence: 0.75,
    metadata: {
      discoveryRunId: randomUUID(),
      timestamp: new Date().toISOString(),
      durationMs: 0,
      version: "1.0",
    },
  };

  console.log("============================================================");
  console.log("LLM SQL Generator Manual Test");
  console.log("============================================================");
  console.log(`Customer ID : ${customerId}`);
  console.log(`Model ID    : ${modelId}`);
  console.log(`Question    : ${question}`);
  console.log("------------------------------------------------------------");

  try {
    const result = await generateSQLWithLLM(context, customerId, modelId);

    console.log("\n✅ Generation successful!\n");
    console.log("Generated SQL:");
    console.log(result.sql);
    console.log("\nExecution Plan:");
    console.log(JSON.stringify(result.executionPlan, null, 2));
    console.log("\nAssumptions:");
    console.log(JSON.stringify(result.assumptions, null, 2));
  } catch (error) {
    console.error("\n❌ Generation failed.");
    console.error(error);
    process.exit(1);
  }
}

main();
