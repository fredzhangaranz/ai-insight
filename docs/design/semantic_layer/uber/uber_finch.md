Uber 的财务团队受不了了。他们每天要在 Presto、IBM Planning Analytics、Oracle EPM、Google Docs 这些系统之间疯狂切换，就为了找一个简单的数据。

更崩溃的是，很多时候还得自己写 SQL，翻文档查字段名，或者干脆提交申请等数据团队跑报表，一等就是几个小时甚至几天。

于是他们用 AI 造了一个叫 Finch 的智能体，彻底解决了这个问题。现在只需要在 Slack 里用自然语言问一句，几秒钟就能拿到答案。

这个故事其实挺有意思的，让我跟你细说下这个 AI 落地案例。

首先我们来看看他们财务分析师之前的日常：你需要查上季度某个地区的总订单额，听起来很简单对吧？但实际操作是：

先登录 Presto 查一部分，再切到 IBM Planning Analytics 找另一部分，然后打开 Oracle EPM 核对，最后还得去 Google Docs 翻历史记录。

如果数据结构复杂一点，你还得自己写 SQL 查询，翻着文档查字段名。

更要命的是，很多时候你根本写不出来那个查询，只能提交申请给数据团队。

然后就是漫长的等待，几个小时到几天不等。等数据拿到手，会议早就开完了，决策早就做了，你手里的数据已经失去了时效性。

Uber 工程团队意识到这个问题的严重性。对于一家每天处理数百万笔交易的公司来说，每一分钟的数据延迟都可能影响重大决策。

所以他们决定彻底改变这个流程，打造了一个叫 Finch 的 AI 数据助手。

Finch 的核心理念特别简单：

让查数据变得像发消息一样简单。它直接集成在 Slack 里，你只需要用自然语言提问，比如“2024 年第四季度美国和加拿大地区的总订单额是多少”，

Finch 就会自动帮你找到正确的数据表，生成 SQL 查询，检查权限，执行查询，然后把结果直接发回 Slack。整个过程只需要几秒钟。

这背后，其实 Uber 没有让 AI 直接面对他们庞大复杂的数据库，而是先做了数据治理，创建了精简的单表数据集市。

然后他们在上面构建了一个语义层，用 OpenSearch 存储自然语言和数据库字段之间的映射关系。比如当你说“US&C”的时候，系统知道你说的是“美国和加拿大地区”这个特定的数据列和值。

整个系统采用了多智能体架构。用户的问题先到达一个监督代理，它判断这是什么类型的请求，然后路由到对应的子代理。

比如数据查询请求会交给 SQL Writer Agent，它从 OpenSearch 获取元数据，构建正确的 SQL 查询，执行并返回结果。

整个过程中，Slack 会实时显示进度：“正在识别数据源““正在构建查询”“正在执行查询”，让用户知道系统在做什么。

如果返回的数据量太大，Finch 还会自动导出到 Google Sheets，直接发给你链接。用户甚至可以追问，比如“跟 2023 年第四季度对比一下”，Finch 会基于对话上下文给出新的结果。

安全性也做得很扎实。Finch 内置了基于角色的访问控制，确保每个人只能看到自己有权限访问的财务数据。而且系统设计时就考虑了模块化，可以轻松替换底层的大语言模型，也可以扩展新的数据源。

为了保证准确性，Uber 建立了严格的测试体系。

他们维护了一套“黄金查询”，也就是标准答案，持续验证每个子代理的输出是否正确。还会做回归测试，重跑历史查询，确保系统更新后不会出现准确率下降的情况。

性能优化上也下了功夫。

系统会预取常用指标，让高频查询几乎是秒回。多个子代理可以并行工作，大幅降低延迟。SQL 查询也做了优化，减少数据库负载。

现在 Finch 已经在 Uber 的财务团队全面使用了。那些原本需要几小时甚至几天才能拿到的数据，现在几秒钟就能在 Slack 里得到答案。分析师们终于可以把时间花在真正的分析上，而不是花在找数据和等数据上。

而在他们的未来规划中，Uber 准备为 CEO 和 CFO 这样的高管用户增加一个“人工验证”环节，关键数据会先让领域专家审核一遍再给出最终结果，确保高风险决策的数据万无一失。

他们还在扩展 Finch 的能力，从简单的数据查询延伸到预测、报告生成、自动化分析这些更复杂的财务场景。

这个案例给我们的启发其实挺深刻的。AI 产品的价值不在于技术有多炫酷，而在于它是否真正解决了用户的痛点。

Uber 没有去追求最先进的模型或者最复杂的架构，而是专注于把一个真实的业务问题解决得彻底。

数据治理、语义层、多智能体协作、严格的测试体系，这些看起来不那么性感的基础工作，才是让 AI 系统真正可靠的关键。
