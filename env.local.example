# Development Environment Configuration
# Copy this file to .env.local and update with your actual values
# cp env.local.example .env.local

# =============================================================================
# DATABASE CONFIGURATION (Optional for development)
# =============================================================================
# For development, you can use the included PostgreSQL container
DATABASE_URL=postgresql://user:password@localhost:5432/insight_gen_db

# Connection string encryption (generate 32-byte hex string: `openssl rand -hex 32`)
# DB_ENCRYPTION_KEY=0000000000000000000000000000000000000000000000000000000000000000

# =============================================================================
# AI SERVICE CONFIGURATION
# =============================================================================
# Add your API keys below to enable the corresponding AI providers

# Anthropic Claude Configuration
# Get your API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-api03-your-anthropic-key-here

# Google Vertex AI Configuration
# Get your project ID and credentials from: https://console.cloud.google.com/
# GOOGLE_CLOUD_PROJECT=your-google-project-id
# GOOGLE_CLOUD_LOCATION=us-central1

# Open WebUI Configuration (for local LLM support)
# Configure these if you want to use Open WebUI for local model inference
# OPENWEBUI_BASE_URL=http://localhost:8080
# OPENWEBUI_API_KEY=your-openwebui-api-key
# OPENWEBUI_MODEL_ID=llama3.1:8b # Optional: specify a default model for the provider
# OPENWEBUI_TIMEOUT=30000

# =============================================================================
# AI MODEL SELECTION
# =============================================================================
# Choose your preferred AI model for each provider (optional, has defaults)

# Anthropic Claude model (optional)
# Supported models: claude-3-5-sonnet-latest, claude-3-opus-latest
ANTHROPIC_DEFAULT_MODEL_NAME=claude-3-5-sonnet-latest

# Google Gemini model (optional)
# Supported models: gemini-2.5-pro, gemini-1.5-flash-latest
GOOGLE_DEFAULT_MODEL_NAME=gemini-2.5-pro

# Open WebUI model (optional)
# Specify the model ID available in your Open WebUI instance
# Example: llama3.1:8b, mistral:7b, etc.
# OPENWEBUI_DEFAULT_MODEL_NAME=llama3.1:8b

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
NODE_ENV=development
PORT=3005

# =============================================================================
# AUTHENTICATION & SESSION
# =============================================================================
# NextAuth configuration (see docs/design/login/login_design.md)
NEXTAUTH_SECRET=your-secret-key-here-change-in-production
NEXTAUTH_URL=http://localhost:3005
NEXTAUTH_SESSION_MAX_AGE=604800  # 7 days

# Bootstrap admin credentials (used by seed-default-admin script)
ADMIN_USERNAME=admin
ADMIN_PASSWORD=ChangeMe123!
ADMIN_EMAIL=admin@yourcompany.local
ADMIN_FULL_NAME=System Administrator

# Feature flag to safely enable login during rollout
AUTH_SYSTEM_ENABLED=false

# =============================================================================
# FEATURE FLAGS — CHART INSIGHTS (Stage 1)
# =============================================================================
# Server-side flags (API/pages)
CHART_INSIGHTS_API_ENABLED=false
CHART_INSIGHTS_ENABLED=false
# Client-side flag (buttons/visibility in client components)
NEXT_PUBLIC_CHART_INSIGHTS_ENABLED=false

# =============================================================================
# FEATURE FLAGS — TEMPLATE SYSTEM (Stage 0)
# =============================================================================
# Server-side flag for template system MVP (default off until DB path is ready)
AI_TEMPLATES_ENABLED=false
